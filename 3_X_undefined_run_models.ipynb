{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import Normalize\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "505c7de3-82a7-4e5b-9a19-2a88f24f7d9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idf_df = pd.read_csv('transac_idf_cleaned.csv')\n",
    "# db cleaned is without all real estate > 30000€/m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe97ac41-3100-49e5-85bb-1a1d4da02d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define potentials data X => run test on all\n",
    "X = idf_df[['longitude', 'latitude','n_pieces','type_bat']].values\n",
    "y = idf_df['prix_m2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ad9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41595f1d-170e-412d-a0fb-5eeb34506e15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.40375064, 48.83624849,  2.        ,  1.        ],\n",
       "       [ 2.348148  , 48.86560434,  1.        ,  1.        ],\n",
       "       [ 2.32468916, 48.88330859,  3.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 2.21748065, 48.99549225,  2.        ,  1.        ],\n",
       "       [ 2.3147687 , 48.97772502,  4.        ,  1.        ],\n",
       "       [ 2.21243488, 49.0221078 ,  3.        ,  1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b372c6d3-6569-43e1-85c3-b714d66680dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10997.        , 11630.76923077, 11271.18644068, ...,\n",
       "        2443.39622642,  6546.39175258,  2428.57142857])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e96a42d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle: LR avec params optimaux: {'fit_intercept': True, 'positive': False} donne erreur =\n",
      "3762.083911769643\n",
      "Modèle: DTR avec params optimaux: {'max_depth': 7, 'min_samples_leaf': 25} donne erreur =\n",
      "2316.2477799342596\n",
      "Modèle: RFR avec params optimaux: {'max_depth': 25} donne erreur =\n",
      "2088.1639427678324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params_grid = {\n",
    "                'LR': {\n",
    "                    'model': LinearRegression(),\n",
    "                    'params': {\n",
    "                        'fit_intercept': [True, False],\n",
    "                        'positive': [True, False]\n",
    "                    }\n",
    "                },\n",
    "                'DTR': {\n",
    "                    'model': DecisionTreeRegressor(),\n",
    "                    'params': {\n",
    "                        'max_depth': list(range(4, 8)),\n",
    "                        'min_samples_leaf': list(range(25,50))\n",
    "                    }\n",
    "                },\n",
    "                'RFR': {\n",
    "                    'model': RandomForestRegressor(),\n",
    "                    'params': {\n",
    "                        'max_depth': [25, 50]\n",
    "                    }\n",
    "                } \n",
    "            }\n",
    "\n",
    "for model_name, model_config in params_grid.items():\n",
    "    gs = GridSearchCV(estimator=model_config['model'], \n",
    "                      param_grid=model_config['params'])\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(f'Modèle: {model_name} avec params optimaux: {gs.best_params_} donne erreur =')\n",
    "    print(np.sqrt(mean_squared_error(y_test, gs.best_estimator_.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fa04e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_fit = DecisionTreeRegressor(max_depth=7, min_samples_leaf=49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f1109cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This DecisionTreeRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(best_model_fit\u001b[38;5;241m.\u001b[39mfeature_importances_, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_pieces\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype_bat\u001b[39m\u001b[38;5;124m'\u001b[39m], columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar()\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:659\u001b[0m, in \u001b[0;36mBaseDecisionTree.feature_importances_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeature_importances_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    643\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the feature importances.\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \n\u001b[0;32m    645\u001b[0m \u001b[38;5;124;03m    The importance of a feature is computed as the (normalized) total\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;124;03m        (Gini importance).\u001b[39;00m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 659\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mcompute_feature_importances()\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1462\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1462\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This DecisionTreeRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "pd.DataFrame(best_model_fit.feature_importances_, index=['longitude', 'latitude', 'n_pieces', 'type_bat'], columns=['Importance']).plot.bar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
